# æ€§èƒ½ä¼˜åŒ–æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†VGOå¾®æœåŠ¡çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ã€æŠ€æœ¯å’Œæœ€ä½³å®è·µã€‚

## ğŸ¯ æ€§èƒ½ç›®æ ‡

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ç±»å‹ | ç›®æ ‡å€¼ | ç›‘æ§æ–¹å¼ |
|----------|--------|----------|
| APIå“åº”æ—¶é—´ | P95 < 200ms | Prometheus + Grafana |
| APIååé‡ | > 1000 RPS | è´Ÿè½½æµ‹è¯• |
| æ•°æ®åº“æŸ¥è¯¢ | P95 < 50ms | æ…¢æŸ¥è¯¢æ—¥å¿— |
| å†…å­˜ä½¿ç”¨ | < 512MB | å†…å­˜ç›‘æ§ |
| CPUä½¿ç”¨ç‡ | < 70% | ç³»ç»Ÿç›‘æ§ |
| é”™è¯¯ç‡ | < 0.1% | é”™è¯¯ç›‘æ§ |

### æ€§èƒ½æµ‹è¯•é‡‘å­—å¡”

```mermaid
graph TB
    subgraph "æ€§èƒ½æµ‹è¯•å±‚æ¬¡"
        A["å‹åŠ›æµ‹è¯•<br/>æé™è´Ÿè½½æµ‹è¯•"]
        B["è´Ÿè½½æµ‹è¯•<br/>é¢„æœŸè´Ÿè½½æµ‹è¯•"]
        C["åŸºå‡†æµ‹è¯•<br/>å•ç»„ä»¶æ€§èƒ½æµ‹è¯•"]
    end
    
    style A fill:#ff6b6b
    style B fill:#ffd93d
    style C fill:#6bcf7f
```

## ğŸš€ åº”ç”¨å±‚ä¼˜åŒ–

### 1. Goè¯­è¨€ä¼˜åŒ–

#### å†…å­˜ç®¡ç†ä¼˜åŒ–

```go
package optimization

import (
    "context"
    "sync"
    "time"
)

// å¯¹è±¡æ± ä¼˜åŒ–
type UserPool struct {
    pool sync.Pool
}

func NewUserPool() *UserPool {
    return &UserPool{
        pool: sync.Pool{
            New: func() interface{} {
                return &User{}
            },
        },
    }
}

func (p *UserPool) Get() *User {
    return p.pool.Get().(*User)
}

func (p *UserPool) Put(user *User) {
    // é‡ç½®å¯¹è±¡çŠ¶æ€
    user.Reset()
    p.pool.Put(user)
}

// ä½¿ç”¨å¯¹è±¡æ± çš„æœåŠ¡
type UserService struct {
    repo     UserRepository
    userPool *UserPool
}

func (s *UserService) ProcessUsers(ctx context.Context, userIDs []string) ([]*User, error) {
    users := make([]*User, 0, len(userIDs))
    
    for _, id := range userIDs {
        // ä»å¯¹è±¡æ± è·å–ç”¨æˆ·å¯¹è±¡
        user := s.userPool.Get()
        defer s.userPool.Put(user)
        
        if err := s.repo.LoadUser(ctx, id, user); err != nil {
            return nil, err
        }
        
        // å¤åˆ¶ç”¨æˆ·æ•°æ®ï¼Œé¿å…æ± å¯¹è±¡è¢«ä¿®æ”¹
        userCopy := *user
        users = append(users, &userCopy)
    }
    
    return users, nil
}

// å­—ç¬¦ä¸²æ„å»ºä¼˜åŒ–
func BuildQuery(conditions []string) string {
    if len(conditions) == 0 {
        return ""
    }
    
    // é¢„åˆ†é…å®¹é‡ï¼Œé¿å…å¤šæ¬¡å†…å­˜åˆ†é…
    var builder strings.Builder
    builder.Grow(len(conditions) * 20) // ä¼°ç®—æ€»é•¿åº¦
    
    builder.WriteString("SELECT * FROM users WHERE ")
    
    for i, condition := range conditions {
        if i > 0 {
            builder.WriteString(" AND ")
        }
        builder.WriteString(condition)
    }
    
    return builder.String()
}

// åˆ‡ç‰‡é¢„åˆ†é…ä¼˜åŒ–
func ProcessLargeDataset(data []DataItem) []ProcessedItem {
    // é¢„åˆ†é…åˆ‡ç‰‡å®¹é‡ï¼Œé¿å…åŠ¨æ€æ‰©å®¹
    result := make([]ProcessedItem, 0, len(data))
    
    for _, item := range data {
        processed := ProcessItem(item)
        result = append(result, processed)
    }
    
    return result
}

// é¿å…ä¸å¿…è¦çš„å†…å­˜åˆ†é…
func (s *UserService) ValidateUsers(users []*User) []error {
    var errors []error // å»¶è¿Ÿåˆ†é…ï¼Œåªåœ¨éœ€è¦æ—¶åˆ†é…
    
    for _, user := range users {
        if err := s.validateUser(user); err != nil {
            if errors == nil {
                errors = make([]error, 0, len(users)) // é¦–æ¬¡åˆ†é…
            }
            errors = append(errors, err)
        }
    }
    
    return errors
}
```

#### å¹¶å‘ä¼˜åŒ–

```go
// å·¥ä½œæ± æ¨¡å¼
type WorkerPool struct {
    workerCount int
    jobQueue    chan Job
    workers     []*Worker
    wg          sync.WaitGroup
}

type Job struct {
    ID   string
    Data interface{}
    Done chan Result
}

type Result struct {
    Data  interface{}
    Error error
}

type Worker struct {
    id       int
    jobQueue chan Job
    quit     chan bool
    handler  JobHandler
}

type JobHandler func(Job) Result

func NewWorkerPool(workerCount int, queueSize int, handler JobHandler) *WorkerPool {
    pool := &WorkerPool{
        workerCount: workerCount,
        jobQueue:    make(chan Job, queueSize),
        workers:     make([]*Worker, workerCount),
    }
    
    // åˆ›å»ºå·¥ä½œè€…
    for i := 0; i < workerCount; i++ {
        worker := &Worker{
            id:       i,
            jobQueue: pool.jobQueue,
            quit:     make(chan bool),
            handler:  handler,
        }
        pool.workers[i] = worker
    }
    
    return pool
}

func (p *WorkerPool) Start() {
    for _, worker := range p.workers {
        p.wg.Add(1)
        go worker.start(&p.wg)
    }
}

func (p *WorkerPool) Stop() {
    for _, worker := range p.workers {
        worker.quit <- true
    }
    p.wg.Wait()
}

func (p *WorkerPool) Submit(job Job) {
    p.jobQueue <- job
}

func (w *Worker) start(wg *sync.WaitGroup) {
    defer wg.Done()
    
    for {
        select {
        case job := <-w.jobQueue:
            result := w.handler(job)
            job.Done <- result
        case <-w.quit:
            return
        }
    }
}

// ä½¿ç”¨å·¥ä½œæ± å¤„ç†æ‰¹é‡ä»»åŠ¡
func (s *UserService) ProcessUsersBatch(ctx context.Context, userIDs []string) ([]*User, error) {
    workerPool := NewWorkerPool(10, 100, func(job Job) Result {
        userID := job.Data.(string)
        user, err := s.repo.GetByID(ctx, userID)
        return Result{Data: user, Error: err}
    })
    
    workerPool.Start()
    defer workerPool.Stop()
    
    // æäº¤ä»»åŠ¡
    results := make([]chan Result, len(userIDs))
    for i, userID := range userIDs {
        done := make(chan Result, 1)
        results[i] = done
        
        job := Job{
            ID:   userID,
            Data: userID,
            Done: done,
        }
        workerPool.Submit(job)
    }
    
    // æ”¶é›†ç»“æœ
    users := make([]*User, 0, len(userIDs))
    for _, resultChan := range results {
        result := <-resultChan
        if result.Error != nil {
            return nil, result.Error
        }
        users = append(users, result.Data.(*User))
    }
    
    return users, nil
}

// é™æµå™¨
type RateLimiter struct {
    tokens chan struct{}
    ticker *time.Ticker
}

func NewRateLimiter(rate int) *RateLimiter {
    rl := &RateLimiter{
        tokens: make(chan struct{}, rate),
        ticker: time.NewTicker(time.Second / time.Duration(rate)),
    }
    
    // åˆå§‹å¡«å……ä»¤ç‰Œ
    for i := 0; i < rate; i++ {
        rl.tokens <- struct{}{}
    }
    
    // å®šæœŸæ·»åŠ ä»¤ç‰Œ
    go func() {
        for range rl.ticker.C {
            select {
            case rl.tokens <- struct{}{}:
            default:
                // ä»¤ç‰Œæ¡¶å·²æ»¡
            }
        }
    }()
    
    return rl
}

func (rl *RateLimiter) Wait(ctx context.Context) error {
    select {
    case <-rl.tokens:
        return nil
    case <-ctx.Done():
        return ctx.Err()
    }
}

func (rl *RateLimiter) Close() {
    rl.ticker.Stop()
}
```

### 2. HTTPæœåŠ¡ä¼˜åŒ–

#### è¿æ¥æ± ä¼˜åŒ–

```go
package http

import (
    "net"
    "net/http"
    "time"
)

// HTTPå®¢æˆ·ç«¯ä¼˜åŒ–é…ç½®
func NewOptimizedHTTPClient() *http.Client {
    transport := &http.Transport{
        // è¿æ¥æ± é…ç½®
        MaxIdleConns:        100,              // æœ€å¤§ç©ºé—²è¿æ¥æ•°
        MaxIdleConnsPerHost: 20,               // æ¯ä¸ªä¸»æœºæœ€å¤§ç©ºé—²è¿æ¥æ•°
        MaxConnsPerHost:     50,               // æ¯ä¸ªä¸»æœºæœ€å¤§è¿æ¥æ•°
        IdleConnTimeout:     90 * time.Second, // ç©ºé—²è¿æ¥è¶…æ—¶
        
        // TCPé…ç½®
        DialContext: (&net.Dialer{
            Timeout:   10 * time.Second, // è¿æ¥è¶…æ—¶
            KeepAlive: 30 * time.Second, // Keep-Aliveé—´éš”
        }).DialContext,
        
        // TLSé…ç½®
        TLSHandshakeTimeout:   10 * time.Second,
        ResponseHeaderTimeout: 10 * time.Second,
        ExpectContinueTimeout: 1 * time.Second,
        
        // ç¦ç”¨HTTP/2ï¼ˆå¦‚æœéœ€è¦ï¼‰
        ForceAttemptHTTP2: false,
    }
    
    return &http.Client{
        Transport: transport,
        Timeout:   30 * time.Second, // æ€»è¶…æ—¶æ—¶é—´
    }
}

// HTTPæœåŠ¡å™¨ä¼˜åŒ–é…ç½®
func NewOptimizedHTTPServer(handler http.Handler) *http.Server {
    return &http.Server{
        Handler: handler,
        
        // è¶…æ—¶é…ç½®
        ReadTimeout:       10 * time.Second,
        ReadHeaderTimeout: 5 * time.Second,
        WriteTimeout:      10 * time.Second,
        IdleTimeout:       120 * time.Second,
        
        // ç¼“å†²åŒºå¤§å°
        MaxHeaderBytes: 1 << 20, // 1MB
    }
}

// å“åº”å‹ç¼©ä¸­é—´ä»¶
func CompressionMiddleware() func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            // æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ”¯æŒå‹ç¼©
            if !strings.Contains(r.Header.Get("Accept-Encoding"), "gzip") {
                next.ServeHTTP(w, r)
                return
            }
            
            // è®¾ç½®å‹ç¼©å“åº”å¤´
            w.Header().Set("Content-Encoding", "gzip")
            w.Header().Set("Vary", "Accept-Encoding")
            
            // åˆ›å»ºgzipå†™å…¥å™¨
            gz := gzip.NewWriter(w)
            defer gz.Close()
            
            // åŒ…è£…å“åº”å†™å…¥å™¨
            gzw := &gzipResponseWriter{
                ResponseWriter: w,
                Writer:         gz,
            }
            
            next.ServeHTTP(gzw, r)
        })
    }
}

type gzipResponseWriter struct {
    http.ResponseWriter
    io.Writer
}

func (w *gzipResponseWriter) Write(b []byte) (int, error) {
    return w.Writer.Write(b)
}
```

#### ç¼“å­˜ä¼˜åŒ–

```go
// å¤šçº§ç¼“å­˜å®ç°
type MultiLevelCache struct {
    l1 *sync.Map           // å†…å­˜ç¼“å­˜
    l2 *redis.Client       // Redisç¼“å­˜
    l3 Database            // æ•°æ®åº“
    
    l1TTL time.Duration
    l2TTL time.Duration
}

type CacheItem struct {
    Data      interface{}
    ExpiresAt time.Time
}

func NewMultiLevelCache(redisClient *redis.Client, db Database) *MultiLevelCache {
    return &MultiLevelCache{
        l1:    &sync.Map{},
        l2:    redisClient,
        l3:    db,
        l1TTL: 5 * time.Minute,
        l2TTL: 30 * time.Minute,
    }
}

func (c *MultiLevelCache) Get(ctx context.Context, key string) (interface{}, error) {
    // L1ç¼“å­˜æŸ¥è¯¢
    if item, ok := c.l1.Load(key); ok {
        cacheItem := item.(*CacheItem)
        if time.Now().Before(cacheItem.ExpiresAt) {
            return cacheItem.Data, nil
        }
        c.l1.Delete(key) // åˆ é™¤è¿‡æœŸé¡¹
    }
    
    // L2ç¼“å­˜æŸ¥è¯¢
    data, err := c.l2.Get(ctx, key).Bytes()
    if err == nil {
        var value interface{}
        if err := json.Unmarshal(data, &value); err == nil {
            // å›å¡«L1ç¼“å­˜
            c.setL1(key, value)
            return value, nil
        }
    }
    
    // L3æ•°æ®åº“æŸ¥è¯¢
    value, err := c.l3.Get(ctx, key)
    if err != nil {
        return nil, err
    }
    
    // å›å¡«ç¼“å­˜
    go func() {
        c.setL1(key, value)
        c.setL2(ctx, key, value)
    }()
    
    return value, nil
}

func (c *MultiLevelCache) Set(ctx context.Context, key string, value interface{}) error {
    // åŒæ—¶è®¾ç½®æ‰€æœ‰ç¼“å­˜å±‚
    c.setL1(key, value)
    return c.setL2(ctx, key, value)
}

func (c *MultiLevelCache) setL1(key string, value interface{}) {
    item := &CacheItem{
        Data:      value,
        ExpiresAt: time.Now().Add(c.l1TTL),
    }
    c.l1.Store(key, item)
}

func (c *MultiLevelCache) setL2(ctx context.Context, key string, value interface{}) error {
    data, err := json.Marshal(value)
    if err != nil {
        return err
    }
    return c.l2.Set(ctx, key, data, c.l2TTL).Err()
}

// ç¼“å­˜é¢„çƒ­
func (c *MultiLevelCache) Warmup(ctx context.Context, keys []string) error {
    // å¹¶å‘é¢„çƒ­
    sem := make(chan struct{}, 10) // é™åˆ¶å¹¶å‘æ•°
    var wg sync.WaitGroup
    
    for _, key := range keys {
        wg.Add(1)
        go func(k string) {
            defer wg.Done()
            sem <- struct{}{}
            defer func() { <-sem }()
            
            _, _ = c.Get(ctx, k) // å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­é¢„çƒ­å…¶ä»–é”®
        }(key)
    }
    
    wg.Wait()
    return nil
}
```

## ğŸ—„ï¸ æ•°æ®åº“ä¼˜åŒ–

### 1. PostgreSQLä¼˜åŒ–

#### è¿æ¥æ± ä¼˜åŒ–

```go
package database

import (
    "database/sql"
    "time"
    
    _ "github.com/lib/pq"
)

// æ•°æ®åº“è¿æ¥æ± é…ç½®
type DBConfig struct {
    Host            string        `json:"host"`
    Port            int           `json:"port"`
    Database        string        `json:"database"`
    Username        string        `json:"username"`
    Password        string        `json:"password"`
    MaxOpenConns    int           `json:"max_open_conns"`
    MaxIdleConns    int           `json:"max_idle_conns"`
    ConnMaxLifetime time.Duration `json:"conn_max_lifetime"`
    ConnMaxIdleTime time.Duration `json:"conn_max_idle_time"`
}

func NewOptimizedDB(cfg DBConfig) (*sql.DB, error) {
    dsn := fmt.Sprintf(
        "host=%s port=%d dbname=%s user=%s password=%s sslmode=disable",
        cfg.Host, cfg.Port, cfg.Database, cfg.Username, cfg.Password,
    )
    
    db, err := sql.Open("postgres", dsn)
    if err != nil {
        return nil, err
    }
    
    // è¿æ¥æ± é…ç½®
    db.SetMaxOpenConns(cfg.MaxOpenConns)       // æœ€å¤§æ‰“å¼€è¿æ¥æ•°
    db.SetMaxIdleConns(cfg.MaxIdleConns)       // æœ€å¤§ç©ºé—²è¿æ¥æ•°
    db.SetConnMaxLifetime(cfg.ConnMaxLifetime) // è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´
    db.SetConnMaxIdleTime(cfg.ConnMaxIdleTime) // è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
    
    // æµ‹è¯•è¿æ¥
    if err := db.Ping(); err != nil {
        return nil, err
    }
    
    return db, nil
}

// é»˜è®¤ä¼˜åŒ–é…ç½®
func DefaultDBConfig() DBConfig {
    return DBConfig{
        MaxOpenConns:    25,                // æœ€å¤§æ‰“å¼€è¿æ¥æ•°
        MaxIdleConns:    5,                 // æœ€å¤§ç©ºé—²è¿æ¥æ•°
        ConnMaxLifetime: 30 * time.Minute,  // è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´
        ConnMaxIdleTime: 5 * time.Minute,   // è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
    }
}
```

#### æŸ¥è¯¢ä¼˜åŒ–

```go
// æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–
func (r *UserRepository) GetUsersByIDs(ctx context.Context, ids []string) ([]*User, error) {
    if len(ids) == 0 {
        return []*User{}, nil
    }
    
    // ä½¿ç”¨ANYæ“ä½œç¬¦è¿›è¡Œæ‰¹é‡æŸ¥è¯¢
    query := `
        SELECT id, username, email, created_at 
        FROM users 
        WHERE id = ANY($1) AND deleted_at IS NULL
        ORDER BY created_at DESC
    `
    
    rows, err := r.db.QueryContext(ctx, query, pq.Array(ids))
    if err != nil {
        return nil, fmt.Errorf("failed to query users: %w", err)
    }
    defer rows.Close()
    
    users := make([]*User, 0, len(ids))
    for rows.Next() {
        var user User
        if err := rows.Scan(&user.ID, &user.Username, &user.Email, &user.CreatedAt); err != nil {
            return nil, fmt.Errorf("failed to scan user: %w", err)
        }
        users = append(users, &user)
    }
    
    return users, rows.Err()
}

// åˆ†é¡µæŸ¥è¯¢ä¼˜åŒ–
func (r *UserRepository) ListUsers(ctx context.Context, opts ListOptions) (*UserList, error) {
    // ä½¿ç”¨æ¸¸æ ‡åˆ†é¡µè€Œä¸æ˜¯OFFSET
    var query string
    var args []interface{}
    
    if opts.Cursor != "" {
        query = `
            SELECT id, username, email, created_at 
            FROM users 
            WHERE created_at < $1 AND deleted_at IS NULL
            ORDER BY created_at DESC 
            LIMIT $2
        `
        
        cursorTime, err := time.Parse(time.RFC3339, opts.Cursor)
        if err != nil {
            return nil, fmt.Errorf("invalid cursor: %w", err)
        }
        
        args = []interface{}{cursorTime, opts.Limit}
    } else {
        query = `
            SELECT id, username, email, created_at 
            FROM users 
            WHERE deleted_at IS NULL
            ORDER BY created_at DESC 
            LIMIT $1
        `
        args = []interface{}{opts.Limit}
    }
    
    rows, err := r.db.QueryContext(ctx, query, args...)
    if err != nil {
        return nil, fmt.Errorf("failed to query users: %w", err)
    }
    defer rows.Close()
    
    users := make([]*User, 0, opts.Limit)
    for rows.Next() {
        var user User
        if err := rows.Scan(&user.ID, &user.Username, &user.Email, &user.CreatedAt); err != nil {
            return nil, fmt.Errorf("failed to scan user: %w", err)
        }
        users = append(users, &user)
    }
    
    // è®¡ç®—ä¸‹ä¸€é¡µæ¸¸æ ‡
    var nextCursor string
    if len(users) == opts.Limit {
        nextCursor = users[len(users)-1].CreatedAt.Format(time.RFC3339)
    }
    
    return &UserList{
        Users:      users,
        NextCursor: nextCursor,
        HasMore:    nextCursor != "",
    }, rows.Err()
}

// é¢„ç¼–è¯‘è¯­å¥ä¼˜åŒ–
type PreparedStatements struct {
    getUserByID    *sql.Stmt
    createUser     *sql.Stmt
    updateUser     *sql.Stmt
    deleteUser     *sql.Stmt
}

func NewPreparedStatements(db *sql.DB) (*PreparedStatements, error) {
    ps := &PreparedStatements{}
    
    var err error
    
    // é¢„ç¼–è¯‘å¸¸ç”¨æŸ¥è¯¢
    ps.getUserByID, err = db.Prepare(`
        SELECT id, username, email, created_at 
        FROM users 
        WHERE id = $1 AND deleted_at IS NULL
    `)
    if err != nil {
        return nil, err
    }
    
    ps.createUser, err = db.Prepare(`
        INSERT INTO users (id, username, email, created_at) 
        VALUES ($1, $2, $3, $4)
    `)
    if err != nil {
        return nil, err
    }
    
    ps.updateUser, err = db.Prepare(`
        UPDATE users 
        SET username = $2, email = $3, updated_at = $4 
        WHERE id = $1 AND deleted_at IS NULL
    `)
    if err != nil {
        return nil, err
    }
    
    ps.deleteUser, err = db.Prepare(`
        UPDATE users 
        SET deleted_at = $2 
        WHERE id = $1 AND deleted_at IS NULL
    `)
    if err != nil {
        return nil, err
    }
    
    return ps, nil
}

func (ps *PreparedStatements) Close() error {
    var errs []error
    
    if err := ps.getUserByID.Close(); err != nil {
        errs = append(errs, err)
    }
    if err := ps.createUser.Close(); err != nil {
        errs = append(errs, err)
    }
    if err := ps.updateUser.Close(); err != nil {
        errs = append(errs, err)
    }
    if err := ps.deleteUser.Close(); err != nil {
        errs = append(errs, err)
    }
    
    if len(errs) > 0 {
        return fmt.Errorf("failed to close prepared statements: %v", errs)
    }
    
    return nil
}
```

#### ç´¢å¼•ä¼˜åŒ–

```sql
-- ç”¨æˆ·è¡¨ç´¢å¼•ä¼˜åŒ–

-- ä¸»é”®ç´¢å¼•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
CREATE UNIQUE INDEX users_pkey ON users (id);

-- å”¯ä¸€ç´¢å¼•
CREATE UNIQUE INDEX users_username_key ON users (username) WHERE deleted_at IS NULL;
CREATE UNIQUE INDEX users_email_key ON users (email) WHERE deleted_at IS NULL;

-- å¤åˆç´¢å¼•
CREATE INDEX users_status_created_at_idx ON users (status, created_at DESC) WHERE deleted_at IS NULL;
CREATE INDEX users_created_at_idx ON users (created_at DESC) WHERE deleted_at IS NULL;

-- éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æ´»è·ƒç”¨æˆ·ï¼‰
CREATE INDEX users_active_username_idx ON users (username) WHERE status = 'active' AND deleted_at IS NULL;

-- è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX users_email_lower_idx ON users (LOWER(email)) WHERE deleted_at IS NULL;

-- ç­–ç•¥è¡¨ç´¢å¼•
CREATE INDEX policies_user_id_idx ON policies (user_id) WHERE deleted_at IS NULL;
CREATE INDEX policies_name_idx ON policies (name) WHERE deleted_at IS NULL;
CREATE INDEX policies_status_created_at_idx ON policies (status, created_at DESC) WHERE deleted_at IS NULL;

-- è®¿é—®å¯†é’¥è¡¨ç´¢å¼•
CREATE UNIQUE INDEX access_keys_access_key_id_key ON access_keys (access_key_id) WHERE deleted_at IS NULL;
CREATE INDEX access_keys_user_id_idx ON access_keys (user_id) WHERE deleted_at IS NULL;
CREATE INDEX access_keys_status_idx ON access_keys (status) WHERE deleted_at IS NULL;

-- å®¡è®¡æ—¥å¿—è¡¨ç´¢å¼•ï¼ˆæ—¶é—´åºåˆ—ä¼˜åŒ–ï¼‰
CREATE INDEX audit_logs_user_id_created_at_idx ON audit_logs (user_id, created_at DESC);
CREATE INDEX audit_logs_action_created_at_idx ON audit_logs (action, created_at DESC);
CREATE INDEX audit_logs_created_at_idx ON audit_logs (created_at DESC);

-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æ—¶é—´åˆ†åŒºï¼‰
CREATE TABLE audit_logs_2024_01 PARTITION OF audit_logs 
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE audit_logs_2024_02 PARTITION OF audit_logs 
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

### 2. Redisä¼˜åŒ–

#### Redisé…ç½®ä¼˜åŒ–

```go
package cache

import (
    "context"
    "time"
    
    "github.com/redis/go-redis/v9"
)

// Redisé…ç½®ä¼˜åŒ–
func NewOptimizedRedisClient(addr, password string) *redis.Client {
    return redis.NewClient(&redis.Options{
        Addr:     addr,
        Password: password,
        DB:       0,
        
        // è¿æ¥æ± é…ç½®
        PoolSize:        20,               // è¿æ¥æ± å¤§å°
        MinIdleConns:    5,                // æœ€å°ç©ºé—²è¿æ¥æ•°
        MaxIdleConns:    10,               // æœ€å¤§ç©ºé—²è¿æ¥æ•°
        ConnMaxIdleTime: 5 * time.Minute,  // è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
        ConnMaxLifetime: 30 * time.Minute, // è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´
        
        // è¶…æ—¶é…ç½®
        DialTimeout:  5 * time.Second,
        ReadTimeout:  3 * time.Second,
        WriteTimeout: 3 * time.Second,
        
        // é‡è¯•é…ç½®
        MaxRetries:      3,
        MinRetryBackoff: 8 * time.Millisecond,
        MaxRetryBackoff: 512 * time.Millisecond,
    })
}

// Redisé›†ç¾¤é…ç½®
func NewOptimizedRedisCluster(addrs []string, password string) *redis.ClusterClient {
    return redis.NewClusterClient(&redis.ClusterOptions{
        Addrs:    addrs,
        Password: password,
        
        // è¿æ¥æ± é…ç½®
        PoolSize:        20,
        MinIdleConns:    5,
        ConnMaxIdleTime: 5 * time.Minute,
        ConnMaxLifetime: 30 * time.Minute,
        
        // è¶…æ—¶é…ç½®
        DialTimeout:  5 * time.Second,
        ReadTimeout:  3 * time.Second,
        WriteTimeout: 3 * time.Second,
        
        // é›†ç¾¤é…ç½®
        MaxRedirects:   8,
        ReadOnly:       true,  // å…è®¸ä»ä»èŠ‚ç‚¹è¯»å–
        RouteByLatency: true,  // æŒ‰å»¶è¿Ÿè·¯ç”±
        RouteRandomly:  false, // ä¸éšæœºè·¯ç”±
    })
}
```

#### ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

```go
// ç¼“å­˜é”®ç®¡ç†
type CacheKeyManager struct {
    prefix string
}

func NewCacheKeyManager(prefix string) *CacheKeyManager {
    return &CacheKeyManager{prefix: prefix}
}

func (m *CacheKeyManager) UserKey(userID string) string {
    return fmt.Sprintf("%s:user:%s", m.prefix, userID)
}

func (m *CacheKeyManager) UserListKey(page int, limit int) string {
    return fmt.Sprintf("%s:users:list:%d:%d", m.prefix, page, limit)
}

func (m *CacheKeyManager) PermissionKey(userID, resource, action string) string {
    return fmt.Sprintf("%s:permission:%s:%s:%s", m.prefix, userID, resource, action)
}

// ç¼“å­˜æœåŠ¡ä¼˜åŒ–
type CacheService struct {
    client    *redis.Client
    keyMgr    *CacheKeyManager
    serializer Serializer
}

type Serializer interface {
    Marshal(v interface{}) ([]byte, error)
    Unmarshal(data []byte, v interface{}) error
}

// JSONåºåˆ—åŒ–å™¨
type JSONSerializer struct{}

func (s *JSONSerializer) Marshal(v interface{}) ([]byte, error) {
    return json.Marshal(v)
}

func (s *JSONSerializer) Unmarshal(data []byte, v interface{}) error {
    return json.Unmarshal(data, v)
}

// MessagePackåºåˆ—åŒ–å™¨ï¼ˆæ›´é«˜æ•ˆï¼‰
type MsgPackSerializer struct{}

func (s *MsgPackSerializer) Marshal(v interface{}) ([]byte, error) {
    return msgpack.Marshal(v)
}

func (s *MsgPackSerializer) Unmarshal(data []byte, v interface{}) error {
    return msgpack.Unmarshal(data, v)
}

func NewCacheService(client *redis.Client, keyMgr *CacheKeyManager) *CacheService {
    return &CacheService{
        client:     client,
        keyMgr:     keyMgr,
        serializer: &MsgPackSerializer{}, // ä½¿ç”¨æ›´é«˜æ•ˆçš„åºåˆ—åŒ–å™¨
    }
}

// æ‰¹é‡æ“ä½œä¼˜åŒ–
func (s *CacheService) GetUsers(ctx context.Context, userIDs []string) (map[string]*User, error) {
    if len(userIDs) == 0 {
        return map[string]*User{}, nil
    }
    
    // æ„å»ºç¼“å­˜é”®
    keys := make([]string, len(userIDs))
    for i, id := range userIDs {
        keys[i] = s.keyMgr.UserKey(id)
    }
    
    // æ‰¹é‡è·å–
    values, err := s.client.MGet(ctx, keys...).Result()
    if err != nil {
        return nil, err
    }
    
    // è§£æç»“æœ
    users := make(map[string]*User)
    for i, value := range values {
        if value == nil {
            continue // ç¼“å­˜æœªå‘½ä¸­
        }
        
        var user User
        if err := s.serializer.Unmarshal([]byte(value.(string)), &user); err != nil {
            continue // ååºåˆ—åŒ–å¤±è´¥ï¼Œè·³è¿‡
        }
        
        users[userIDs[i]] = &user
    }
    
    return users, nil
}

// ç®¡é“æ“ä½œä¼˜åŒ–
func (s *CacheService) SetUsers(ctx context.Context, users map[string]*User, ttl time.Duration) error {
    if len(users) == 0 {
        return nil
    }
    
    // ä½¿ç”¨ç®¡é“æ‰¹é‡è®¾ç½®
    pipe := s.client.Pipeline()
    
    for userID, user := range users {
        data, err := s.serializer.Marshal(user)
        if err != nil {
            continue // åºåˆ—åŒ–å¤±è´¥ï¼Œè·³è¿‡
        }
        
        key := s.keyMgr.UserKey(userID)
        pipe.Set(ctx, key, data, ttl)
    }
    
    _, err := pipe.Exec(ctx)
    return err
}

// ç¼“å­˜é¢„çƒ­
func (s *CacheService) WarmupUsers(ctx context.Context, userIDs []string, loader func([]string) (map[string]*User, error)) error {
    // æ£€æŸ¥å“ªäº›ç”¨æˆ·ä¸åœ¨ç¼“å­˜ä¸­
    cached, err := s.GetUsers(ctx, userIDs)
    if err != nil {
        return err
    }
    
    var missing []string
    for _, id := range userIDs {
        if _, exists := cached[id]; !exists {
            missing = append(missing, id)
        }
    }
    
    if len(missing) == 0 {
        return nil // æ‰€æœ‰æ•°æ®éƒ½å·²ç¼“å­˜
    }
    
    // åŠ è½½ç¼ºå¤±çš„æ•°æ®
    users, err := loader(missing)
    if err != nil {
        return err
    }
    
    // ç¼“å­˜æ–°æ•°æ®
    return s.SetUsers(ctx, users, 30*time.Minute)
}
```

## ğŸŒ ç½‘ç»œä¼˜åŒ–

### 1. gRPCä¼˜åŒ–

```go
package grpc

import (
    "context"
    "time"
    
    "google.golang.org/grpc"
    "google.golang.org/grpc/keepalive"
    "google.golang.org/grpc/credentials/insecure"
)

// gRPCå®¢æˆ·ç«¯ä¼˜åŒ–
func NewOptimizedGRPCClient(target string) (*grpc.ClientConn, error) {
    return grpc.Dial(target,
        grpc.WithTransportCredentials(insecure.NewCredentials()),
        
        // è¿æ¥æ± é…ç½®
        grpc.WithDefaultCallOptions(
            grpc.MaxCallRecvMsgSize(4*1024*1024), // 4MB
            grpc.MaxCallSendMsgSize(4*1024*1024), // 4MB
        ),
        
        // Keep-Aliveé…ç½®
        grpc.WithKeepaliveParams(keepalive.ClientParameters{
            Time:                10 * time.Second, // å‘é€keepalive pingçš„é—´éš”
            Timeout:             3 * time.Second,  // ç­‰å¾…keepalive pingå“åº”çš„è¶…æ—¶
            PermitWithoutStream: true,             // å…è®¸åœ¨æ²¡æœ‰æ´»è·ƒæµæ—¶å‘é€keepalive ping
        }),
        
        // è¿æ¥çŠ¶æ€ç›‘æ§
        grpc.WithBlock(),
        grpc.WithTimeout(10*time.Second),
    )
}

// gRPCæœåŠ¡å™¨ä¼˜åŒ–
func NewOptimizedGRPCServer() *grpc.Server {
    return grpc.NewServer(
        // æ¶ˆæ¯å¤§å°é™åˆ¶
        grpc.MaxRecvMsgSize(4*1024*1024), // 4MB
        grpc.MaxSendMsgSize(4*1024*1024), // 4MB
        
        // Keep-Aliveé…ç½®
        grpc.KeepaliveParams(keepalive.ServerParameters{
            Time:    60 * time.Second, // æœåŠ¡å™¨å‘é€keepalive pingçš„é—´éš”
            Timeout: 5 * time.Second,  // ç­‰å¾…keepalive pingå“åº”çš„è¶…æ—¶
        }),
        
        grpc.KeepaliveEnforcementPolicy(keepalive.EnforcementPolicy{
            MinTime:             30 * time.Second, // å®¢æˆ·ç«¯å‘é€keepalive pingçš„æœ€å°é—´éš”
            PermitWithoutStream: true,             // å…è®¸åœ¨æ²¡æœ‰æ´»è·ƒæµæ—¶å‘é€keepalive ping
        }),
        
        // è¿æ¥è¶…æ—¶
        grpc.ConnectionTimeout(10*time.Second),
    )
}

// è¿æ¥æ± ç®¡ç†
type GRPCConnectionPool struct {
    connections []*grpc.ClientConn
    current     int
    mu          sync.RWMutex
}

func NewGRPCConnectionPool(target string, size int) (*GRPCConnectionPool, error) {
    pool := &GRPCConnectionPool{
        connections: make([]*grpc.ClientConn, size),
    }
    
    for i := 0; i < size; i++ {
        conn, err := NewOptimizedGRPCClient(target)
        if err != nil {
            // å…³é—­å·²åˆ›å»ºçš„è¿æ¥
            for j := 0; j < i; j++ {
                pool.connections[j].Close()
            }
            return nil, err
        }
        pool.connections[i] = conn
    }
    
    return pool, nil
}

func (p *GRPCConnectionPool) GetConnection() *grpc.ClientConn {
    p.mu.Lock()
    defer p.mu.Unlock()
    
    conn := p.connections[p.current]
    p.current = (p.current + 1) % len(p.connections)
    
    return conn
}

func (p *GRPCConnectionPool) Close() error {
    p.mu.Lock()
    defer p.mu.Unlock()
    
    var errs []error
    for _, conn := range p.connections {
        if err := conn.Close(); err != nil {
            errs = append(errs, err)
        }
    }
    
    if len(errs) > 0 {
        return fmt.Errorf("failed to close connections: %v", errs)
    }
    
    return nil
}
```

### 2. è´Ÿè½½å‡è¡¡ä¼˜åŒ–

```go
// è´Ÿè½½å‡è¡¡å™¨
type LoadBalancer struct {
    servers []Server
    current int
    mu      sync.RWMutex
}

type Server struct {
    Address string
    Weight  int
    Active  bool
}

// è½®è¯¢è´Ÿè½½å‡è¡¡
func (lb *LoadBalancer) RoundRobin() *Server {
    lb.mu.Lock()
    defer lb.mu.Unlock()
    
    for i := 0; i < len(lb.servers); i++ {
        server := &lb.servers[lb.current]
        lb.current = (lb.current + 1) % len(lb.servers)
        
        if server.Active {
            return server
        }
    }
    
    return nil // æ²¡æœ‰å¯ç”¨æœåŠ¡å™¨
}

// åŠ æƒè½®è¯¢è´Ÿè½½å‡è¡¡
func (lb *LoadBalancer) WeightedRoundRobin() *Server {
    lb.mu.Lock()
    defer lb.mu.Unlock()
    
    totalWeight := 0
    for _, server := range lb.servers {
        if server.Active {
            totalWeight += server.Weight
        }
    }
    
    if totalWeight == 0 {
        return nil
    }
    
    target := rand.Intn(totalWeight)
    current := 0
    
    for _, server := range lb.servers {
        if !server.Active {
            continue
        }
        
        current += server.Weight
        if current > target {
            return &server
        }
    }
    
    return nil
}

// å¥åº·æ£€æŸ¥
func (lb *LoadBalancer) HealthCheck(ctx context.Context) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            lb.checkServers(ctx)
        case <-ctx.Done():
            return
        }
    }
}

func (lb *LoadBalancer) checkServers(ctx context.Context) {
    var wg sync.WaitGroup
    
    for i := range lb.servers {
        wg.Add(1)
        go func(index int) {
            defer wg.Done()
            
            server := &lb.servers[index]
            active := lb.isServerHealthy(ctx, server.Address)
            
            lb.mu.Lock()
            server.Active = active
            lb.mu.Unlock()
        }(i)
    }
    
    wg.Wait()
}

func (lb *LoadBalancer) isServerHealthy(ctx context.Context, address string) bool {
    client := &http.Client{Timeout: 5 * time.Second}
    
    req, err := http.NewRequestWithContext(ctx, "GET", address+"/health", nil)
    if err != nil {
        return false
    }
    
    resp, err := client.Do(req)
    if err != nil {
        return false
    }
    defer resp.Body.Close()
    
    return resp.StatusCode == http.StatusOK
}
```

## ğŸ“Š ç›‘æ§å’Œåˆ†æ

### 1. æ€§èƒ½æŒ‡æ ‡æ”¶é›†

```go
package metrics

import (
    "context"
    "runtime"
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// æ€§èƒ½æŒ‡æ ‡å®šä¹‰
var (
    // HTTPæŒ‡æ ‡
    httpRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )
    
    httpRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10},
        },
        []string{"method", "endpoint"},
    )
    
    // æ•°æ®åº“æŒ‡æ ‡
    dbConnectionsActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "db_connections_active",
            Help: "Number of active database connections",
        },
    )
    
    dbQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "db_query_duration_seconds",
            Help:    "Database query duration in seconds",
            Buckets: []float64{.001, .005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5},
        },
        []string{"query_type"},
    )
    
    // ç¼“å­˜æŒ‡æ ‡
    cacheHitsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_hits_total",
            Help: "Total number of cache hits",
        },
        []string{"cache_type"},
    )
    
    cacheMissesTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_misses_total",
            Help: "Total number of cache misses",
        },
        []string{"cache_type"},
    )
    
    // ç³»ç»ŸæŒ‡æ ‡
    memoryUsage = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "memory_usage_bytes",
            Help: "Memory usage in bytes",
        },
    )
    
    goroutinesActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "goroutines_active",
            Help: "Number of active goroutines",
        },
    )
)

// æŒ‡æ ‡æ”¶é›†å™¨
type MetricsCollector struct {
    db *sql.DB
}

func NewMetricsCollector(db *sql.DB) *MetricsCollector {
    return &MetricsCollector{db: db}
}

// å¯åŠ¨æŒ‡æ ‡æ”¶é›†
func (m *MetricsCollector) Start(ctx context.Context) {
    ticker := time.NewTicker(15 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            m.collectSystemMetrics()
            m.collectDatabaseMetrics()
        case <-ctx.Done():
            return
        }
    }
}

func (m *MetricsCollector) collectSystemMetrics() {
    var memStats runtime.MemStats
    runtime.ReadMemStats(&memStats)
    
    memoryUsage.Set(float64(memStats.Alloc))
    goroutinesActive.Set(float64(runtime.NumGoroutine()))
}

func (m *MetricsCollector) collectDatabaseMetrics() {
    stats := m.db.Stats()
    dbConnectionsActive.Set(float64(stats.OpenConnections))
}

// HTTPæŒ‡æ ‡ä¸­é—´ä»¶
func MetricsMiddleware() func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            start := time.Now()
            
            // åŒ…è£…å“åº”å†™å…¥å™¨ä»¥æ•è·çŠ¶æ€ç 
            rw := &responseWriter{ResponseWriter: w, statusCode: 200}
            
            // æ‰§è¡Œè¯·æ±‚
            next.ServeHTTP(rw, r)
            
            // è®°å½•æŒ‡æ ‡
            duration := time.Since(start).Seconds()
            
            httpRequestsTotal.WithLabelValues(
                r.Method,
                r.URL.Path,
                fmt.Sprintf("%d", rw.statusCode),
            ).Inc()
            
            httpRequestDuration.WithLabelValues(
                r.Method,
                r.URL.Path,
            ).Observe(duration)
        })
    }
}

// æ•°æ®åº“æŒ‡æ ‡è£…é¥°å™¨
func (m *MetricsCollector) WrapDBQuery(queryType string, fn func() error) error {
    start := time.Now()
    err := fn()
    duration := time.Since(start).Seconds()
    
    dbQueryDuration.WithLabelValues(queryType).Observe(duration)
    
    return err
}

// ç¼“å­˜æŒ‡æ ‡è£…é¥°å™¨
func RecordCacheHit(cacheType string) {
    cacheHitsTotal.WithLabelValues(cacheType).Inc()
}

func RecordCacheMiss(cacheType string) {
    cacheMissesTotal.WithLabelValues(cacheType).Inc()
}
```

### 2. æ€§èƒ½åˆ†æå·¥å…·

```bash
#!/bin/bash
# scripts/performance-analysis.sh

SERVICE_URL="http://localhost:8080"
DURATION="60s"
OUTPUT_DIR="./performance-analysis"

mkdir -p $OUTPUT_DIR

echo "Starting performance analysis for $DURATION..."

# æ”¶é›†CPU profile
echo "Collecting CPU profile..."
curl -s "$SERVICE_URL/debug/pprof/profile?seconds=60" > "$OUTPUT_DIR/cpu.prof" &
CPU_PID=$!

# æ”¶é›†å†…å­˜profile
echo "Collecting memory profile..."
curl -s "$SERVICE_URL/debug/pprof/heap" > "$OUTPUT_DIR/heap.prof" &
MEM_PID=$!

# æ”¶é›†goroutine profile
echo "Collecting goroutine profile..."
curl -s "$SERVICE_URL/debug/pprof/goroutine" > "$OUTPUT_DIR/goroutine.prof" &
GOR_PID=$!

# è¿è¡Œè´Ÿè½½æµ‹è¯•
echo "Running load test..."
wrk -t12 -c400 -d60s --latency "$SERVICE_URL/api/v1/users" > "$OUTPUT_DIR/load-test.txt" &
LOAD_PID=$!

# ç›‘æ§ç³»ç»Ÿèµ„æº
echo "Monitoring system resources..."
{
    echo "timestamp,cpu_percent,memory_percent,disk_io,network_io"
    for i in {1..60}; do
        timestamp=$(date +"%Y-%m-%d %H:%M:%S")
        cpu=$(top -l 1 | grep "CPU usage" | awk '{print $3}' | sed 's/%//')
        memory=$(top -l 1 | grep "PhysMem" | awk '{print $2}' | sed 's/M//')
        echo "$timestamp,$cpu,$memory,0,0"
        sleep 1
    done
} > "$OUTPUT_DIR/system-metrics.csv" &
SYS_PID=$!

# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
wait $CPU_PID $MEM_PID $GOR_PID $LOAD_PID $SYS_PID

echo "Performance analysis completed. Results saved to $OUTPUT_DIR"

# ç”Ÿæˆåˆ†ææŠ¥å‘Š
echo "Generating analysis report..."
go tool pprof -top "$OUTPUT_DIR/cpu.prof" > "$OUTPUT_DIR/cpu-analysis.txt"
go tool pprof -top "$OUTPUT_DIR/heap.prof" > "$OUTPUT_DIR/memory-analysis.txt"

echo "Analysis report generated."
echo "View CPU analysis: cat $OUTPUT_DIR/cpu-analysis.txt"
echo "View memory analysis: cat $OUTPUT_DIR/memory-analysis.txt"
echo "View load test results: cat $OUTPUT_DIR/load-test.txt"
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¼€å‘æŒ‡å—](./README.md)
- [æ¶æ„è®¾è®¡](./architecture.md)
- [æµ‹è¯•æŒ‡å—](./testing.md)
- [è°ƒè¯•æŒ‡å—](./debugging.md)
- [APIæ–‡æ¡£](../api/README.md)
- [éƒ¨ç½²æŒ‡å—](../deployment/README.md)